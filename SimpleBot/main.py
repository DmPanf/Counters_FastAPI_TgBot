from ultralytics import YOLO
import cv2
import numpy as np
#from PIL import Image
import io
from fastapi import FastAPI, File, UploadFile, Form, Request  #, HTTPException
from fastapi.responses import StreamingResponse, HTMLResponse  #, JSONResponse
#from fastapi.staticfiles import StaticFiles
#from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
#import json
# from typing import Optional
import base64
from pydantic import BaseModel
import glob
import os
import time
#import re
import json
#import torch
#torch.cuda.is_available = lambda : False  # –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ CPU –¥–ª—è PyTorch
from bboxes import draw_boxes

# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
save_path = './images'
default_mdl_path = './models/'  # –ü—É—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –≥–¥–µ —Ö—Ä–∞–Ω—è—Ç—Å—è –º–æ–¥–µ–ª–∏

app = FastAPI(title="Counters System API for DataSet", version="0.1.2", debug=True)  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ResponseModel(BaseModel):
    image: str
    results: dict

def get_latest_model(path):  # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–æ–¥–µ–ª–∏
    list_of_files = glob.glob(f'{path}*.pt')
    if not list_of_files:
        return None  # –ù–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
    latest_model = max(list_of_files, key=os.path.getctime)  # –í—ã–±–∏—Ä–∞–µ–º —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª
    print(f'‚ôªÔ∏è  Latest Model: {latest_model}')
    return latest_model


# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤
#app.mount('/static', StaticFiles(directory="static"), name="static")
#templates = Jinja2Templates(directory="templates")

def generate_file_name(model_name, file_ext, images_dir='./images'):
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
    current_time = time.strftime("%Y-%m-%d_%H-%M-%S", time.localtime())

    # –í—ã–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–≤—ã—Ö –¥–≤—É—Ö —Ü–∏—Ñ—Ä –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    #model_digits = re.findall(r'\d+', model_name)[:2]
    #model_prefix = ''.join(model_digits)[:2]  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –¥–≤–µ —Ü–∏—Ñ—Ä—ã

    model_prefix = model_name[:2]

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–æ–≤–æ–≥–æ –Ω–æ–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
    existing_files = glob.glob(os.path.join(images_dir, '*.', file_ext))  # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ .jpg
    next_file_number = len(existing_files) + 1

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    file_name = f"{current_time}_{str(next_file_number).zfill(5)}_M{model_prefix}.{file_ext}"

    return file_name


# Get client IP address 
@app.get("/")
async def read_root(request: Request):
    forwarded_for = request.headers.get("x-forwarded-for")
    if forwarded_for:
        client_host = forwarded_for.split(",")[0]
    else:
        client_host = request.client.host
    return {"üì° Client IP: ": client_host}


@app.get('/info')
def read_root():
    return {'Project 2023': 'üìü Counters FastAPI Server - TgeBot\n[–≥. –ú–æ—Å–∫–≤–∞, 2023 –≥.]'}


@app.get('/models')
def list_models():
    models_dir = "models"
    models = []
    sorted_files = sorted(os.listdir(models_dir))

    for filename in sorted_files:
        if filename.endswith(".h5") or filename.endswith(".pt"):  # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π
            models.append(filename)
    #return JSONResponse(content={"Models": models})
    return {"Models": models}


@app.post('/predict')
# async def predict(file: UploadFile = File(...), mdl_name: Optional[str] = Form(None)):
async def predict(file: UploadFile = File(...), mdl_name: str = Form('./models/09_cds2_s-seg_1280_100e.pt')):
    if not file:
        return {"‚ÄºÔ∏è error": "üö∑ No file uploaded"}
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞
    file_ext = file.filename.split('.')[-1].lower()

    # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
    supported_formats = ["jpg", "jpeg", "png", "bmp", "tiff"]
    if file_ext not in supported_formats:
        return {"error": f"Unsupported file format: {file_ext}"}
    
    
    # print("... Received model name:", mdl_name) # –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ !!!
    image_stream = io.BytesIO(await file.read())
    image_stream.seek(0)
    image = cv2.imdecode(np.frombuffer(image_stream.read(), np.uint8), 1)
    image_stream.close()

    if image is None:
        return {"error": "Invalid image file"}

    # –ï—Å–ª–∏ –∏–º—è –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ, —Å–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏
    if mdl_name:
        selected_model = os.path.join(default_mdl_path, mdl_name)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
        if not os.path.exists(selected_model):
            selected_model = get_latest_model(default_mdl_path)
        print(f'‚öñÔ∏è  Selected Model: {selected_model}')
    else:
        selected_model = get_latest_model(default_mdl_path)

    if selected_model is None:
        return {"error": "No model files found"}

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –≤ –ø–∞–º—è—Ç—å
    model = YOLO(selected_model) # if selected_model else None
    # results = model.predict(source=image, imgsz=640, conf=0.25, name="00", save_txt=True, save_conf=True)
    results = model.predict(source=image, imgsz=640, conf=0.25)

    # Save the image +++++++++++++++++++++++++++++++
    model_name = os.path.basename(selected_model)
    current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

    # file_name = generate_file_name(model_name, file_ext)
    file_name = generate_file_name(model_name, "jpg")
    file_path = f"{save_path}/{file_name}"
    cv2.imwrite(file_path, image)
    # ===============================================

    image, counter, number, speed, wh_check = draw_boxes(image, results)

    # Save the image to BytesIO object and send it as a response with Content-Disposition header
    is_success, buffer = cv2.imencode(".jpg", image)
    if not is_success:
        return {"error": "Failed to save the image"}

    image_data = {
        "model_name": model_name,
        "object_count": number,
        "inference": speed,
        "current_time": current_time,
        "counter": counter,
        "wh_check": wh_check,
        "file_name": file_name
    }
    # print(f'\n{image_data}\n')

    # –ó–∞–º–µ–Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –Ω–∞ .json
    json_file_name = file_name.rsplit('.', 1)[0] + '.json'
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ JSON —Ñ–∞–π–ª
    with open(f"{save_path}/{json_file_name}", 'w') as json_file:
        json.dump(image_data, json_file, indent=4)


    # ++++++++++++++++++++ Image Data ++++++++++++++++++++
    # image_data = {"model_name": selected_model, "mode": mkey}
    img_str = base64.b64encode(buffer).decode()  # Encode the image as base64 string 
    response_data = {
        "image": img_str,
        "results": image_data  # Extract additional data from the model
    }
    # return JSONResponse(content=json.dumps(response_data), media_type="application/json")
    response = ResponseModel(image=img_str, results=image_data)
    return response


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
